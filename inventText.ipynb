{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heading\n",
    "\n",
    "Here is where I explain some things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import spacy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse = 'Flaubert'\n",
    "# There are four options for vector spaces of words, which represent different\n",
    "# discourses, or the ways in which language is used: Trump, Balzac, Sand, Flaubert.\n",
    "# See below.\n",
    "\n",
    "number_of_options = 15\n",
    "# the max number of similar words proposed from the vector space\n",
    "# for each word in the asserted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = 'bien'\n",
    "negative = 'mal'\n",
    "# These two words establish the analogy for finding similar words in the vector space.\n",
    "\n",
    "assertion = u\"Il faut être toujours ivre. Tout est là : c'est l'unique question. Pour ne pas sentir l'horrible fardeau du Temps qui brise vos épaules et vous penche vers la terre, il faut vous enivrer sans trêve.\"\n",
    "# The assertion will be altered by word substitutions based on the above analogy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Trump':\n",
    "        ['Trump_model',\n",
    "         # a vector space of words from all of Trump's tweets\n",
    "         \n",
    "         'Trump_pos_dict.pkl',\n",
    "         # a dictionary of all words in the vector space with part-of-speech (POS) tags\n",
    "         \n",
    "         'en',\n",
    "         # the language of the vector space\n",
    "         \n",
    "         ('DT', 'PUNCT', 'IN')\n",
    "         # POS tags for words that will not be replaced in asserted text\n",
    "         \n",
    "        ],\n",
    "    'Balzac':\n",
    "        ['NCF_short_author_Balzac_model',\n",
    "         # vector space of words from 118 volumes by Balzac\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "         # this dictionary is based on a corpus of 1,333 volumes of 19C French texts\n",
    "         \n",
    "         'fr',\n",
    "         ('DET', 'PUNCT')\n",
    "        ],\n",
    "    'Sand':\n",
    "        ['NCF_short_author_Sand_model',\n",
    "         # vector space of words from 70 volumes by Sand\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "         'fr',\n",
    "         ('DET', 'PUNCT')\n",
    "        ],\n",
    "    'Flaubert':\n",
    "        ['NCF_short_author_Flaubert_model',\n",
    "         # vector space of words from 30 volumes by Flaubert\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "         'fr',\n",
    "         ('DET', 'PUNCT')\n",
    "        ]\n",
    "}\n",
    "\n",
    "model = gensim.models.Word2Vec.load(params[discourse][0])\n",
    "pickleFile = open(params[discourse][1], 'rb')\n",
    "posd = pickle.load(pickleFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(params[discourse][2])\n",
    "parsed = nlp(assertion)\n",
    "words = [(w.text.lower(), w.tag_, w.lemma_.lower()) for w in parsed]\n",
    "# Build a list of 3-tuples for each word in the asserted text:\n",
    "# (the word in the asserted text, its POS, its lemma)\n",
    "\n",
    "new_words = []\n",
    "\n",
    "for word in words:\n",
    "    try:\n",
    "        hits = []\n",
    "        # a list of vector space words to be built that will be similar to a word\n",
    "        # in the asserted text.\n",
    "        \n",
    "        psw = word[1].split('__')[0]\n",
    "        # The POS tag for a word in the asserted text.\n",
    "        \n",
    "        #print word[0], word[1], word[2] # for debugging\n",
    "        \n",
    "        for item in model.wv.most_similar(positive=[positive.lower(), word[2]],\n",
    "                                          negative=[negative.lower()],\n",
    "                                          topn=number_of_options):\n",
    "        # Take each word in the asserted text and look for similar words\n",
    "        # in the vector space based on the analogy.\n",
    "        \n",
    "            #print '\\t', item # for debugging\n",
    "            \n",
    "            if posd[item[0]]:\n",
    "            # does the vector-space word have a POS tag?\n",
    "            \n",
    "                psd = next(iter(posd[item[0]])).split('__')[0]\n",
    "                \n",
    "                #print '\\t\\t', psd # for debugging\n",
    "                \n",
    "                if (psw not in params[discourse][3]) and (psw == psd):\n",
    "                # We exclude certain POS words (like determiners and punctuation: see above)\n",
    "                # to maintain readability in the invented text.\n",
    "                # We also select words from the vector space that are the same POS\n",
    "                # as the original word in the asserted text.\n",
    "                \n",
    "                    hits.append(item[0])\n",
    "                    \n",
    "        if len(hits) > 0:\n",
    "        # Did we find at least one vector space word with the same POS?\n",
    "        # If so, display them in parentheses in the invented text.\n",
    "        \n",
    "            replacement = '(' + '|'.join(hits) + ')'\n",
    "            new_words.append(replacement)\n",
    "            \n",
    "        else:\n",
    "        # If we found nothing that matches, use the original word.\n",
    "        \n",
    "            new_words.append(word[0])\n",
    "    except:\n",
    "    # If something weird happens, just use the original word.\n",
    "    \n",
    "        new_words.append(word[0])\n",
    "        \n",
    "        #print 'EXCEPTION', word[0] # for debugging\n",
    "\n",
    "response = ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print assertion, '\\n'\n",
    "print response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
