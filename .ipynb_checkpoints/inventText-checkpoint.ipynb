{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithmic Invention\n",
    "### Mark Wolff<br>Hartwick College\n",
    "#### ELO 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\\>\\>\\> model.wv.most_similar(positive=['femme', 'roi'], negative=['homme'], topn=1)\n",
    "\n",
    "[(u'reine', 0.8085041046142578)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"2100\"\n",
       "            height=\"800\"\n",
       "            src=\"http://www.ghostweather.com/files/word2vecpride/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x102ef8990>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('http://www.ghostweather.com/files/word2vecpride/', 2100, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](NCF_short_author_Flaubert_tsne_plot.svg \"Word Vector Model for Flaubert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import gensim\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "discourse = 'Flaubert'\n",
    "# There are four options for vector spaces of words, which represent\n",
    "# different discourses, or the ways in which language is used: Trump,\n",
    "# Balzac, Sand, Flaubert.\n",
    "# See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "assertion = u\"Il faut être toujours ivre. Tout est là : \" + \\\n",
    "    u\"c'est l'unique question. Pour ne pas sentir l'horrible \" + \\\n",
    "    u\"fardeau du Temps qui brise vos épaules et vous penche \" + \\\n",
    "    u\"vers la terre, il faut vous enivrer sans trêve.\"\n",
    "# The assertion, from Baudelaire's poem Enivrez-vous!, will be altered\n",
    "# by word substitutions based on the analogy below.\n",
    "\n",
    "positive = u'bien'\n",
    "negative = u'mal'\n",
    "# These two words establish the analogy for finding similar words in\n",
    "# the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Flaubert':\n",
    "        ['NCF_short_author_Flaubert_model',\n",
    "         # vector space of words from 30 volumes by Flaubert\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "        # a dictionary of all words in the vector space with\n",
    "         # part-of-speech (POS) tags\n",
    "\n",
    "         'fr',\n",
    "         # the language of the vector space\n",
    "         \n",
    "         ('DET', 'PUNCT')\n",
    "         # POS tags for words that will not be replaced in asserted\n",
    "         # text\n",
    "        ],\n",
    "    'Balzac':\n",
    "        ['NCF_short_author_Balzac_model',\n",
    "         # vector space of words from 118 volumes by Balzac\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "         \n",
    "         'fr',\n",
    "         \n",
    "         ('DET', 'PUNCT')\n",
    "        ],\n",
    "    'Sand':\n",
    "        ['NCF_short_author_Sand_model',\n",
    "         # vector space of words from 70 volumes by Sand\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "         \n",
    "         'fr',\n",
    "         \n",
    "         ('DET', 'PUNCT')\n",
    "        ],\n",
    "    'Trump':\n",
    "        ['Trump_model',\n",
    "         # a vector space of words from all of Trump's tweets\n",
    "         \n",
    "         'Trump_pos_dict.pkl',\n",
    "         \n",
    "         'en',\n",
    "         \n",
    "         ('DT', 'PUNCT', 'IN')\n",
    "        ]\n",
    "}\n",
    "\n",
    "number_of_options = 15\n",
    "# the max number of similar words proposed from the vector space\n",
    "# for each word in the asserted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(params[discourse][0])\n",
    "pickleFile = open(params[discourse][1], 'rb')\n",
    "posd = pickle.load(pickleFile)\n",
    "\n",
    "nlp = spacy.load(params[discourse][2])\n",
    "parsed = nlp(assertion)\n",
    "words = [(w.text.lower(), w.tag_, w.lemma_.lower()) for w in parsed]\n",
    "# Build a list of 3-tuples for each word in the asserted text:\n",
    "# (the word in the asserted text, its POS, its lemma)\n",
    "\n",
    "new_words = []\n",
    "\n",
    "for word in words:\n",
    "    try:\n",
    "        hits = []\n",
    "        # a list of vector space words to be built that will be similar\n",
    "        # to a word in the asserted text.\n",
    "        \n",
    "        psw = word[1].split('__')[0]\n",
    "        # The POS tag for a word in the asserted text.\n",
    "        \n",
    "        #print word[0], word[1], word[2] # for debugging\n",
    "        \n",
    "        for item in model.wv.most_similar(positive=[positive.lower(),\n",
    "                                                    word[2]],\n",
    "                                          negative=[negative.lower()],\n",
    "                                          topn=number_of_options):\n",
    "        # Take each word in the asserted text and look for similar words\n",
    "        # in the vector space based on the analogy.\n",
    "        \n",
    "            #print '\\t', item # for debugging\n",
    "            \n",
    "            if posd[item[0]]:\n",
    "            # does the vector-space word have a POS tag?\n",
    "            \n",
    "                psd = next(iter(posd[item[0]])).split('__')[0]\n",
    "                \n",
    "                #print '\\t\\t', psd # for debugging\n",
    "                \n",
    "                if (psw not in params[discourse][3]) and (psw == psd):\n",
    "                # We exclude certain POS words (like determiners and\n",
    "                # punctuation: see above) to maintain readability in\n",
    "                # the invented text. We also select words from the\n",
    "                # vector space that are the same POS as the original\n",
    "                # word in the asserted text.\n",
    "                \n",
    "                    hits.append(item[0])\n",
    "                    \n",
    "        if len(hits) > 0:\n",
    "        # Did we find at least one vector space word with the same POS?\n",
    "        # If so, display them in parentheses in the invented text.\n",
    "        \n",
    "            replacement = '(' + '|'.join(hits) + ')'\n",
    "            new_words.append(replacement)\n",
    "            \n",
    "        else:\n",
    "        # If we found nothing that matches, use the original word.\n",
    "        \n",
    "            new_words.append(word[0])\n",
    "    except:\n",
    "    # If something weird happens, just use the original word.\n",
    "    \n",
    "        new_words.append(word[0])\n",
    "        \n",
    "        #print 'EXCEPTION', word[0] # for debugging\n",
    "\n",
    "response = ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il faut être toujours ivre. Tout est là : c'est l'unique question. Pour ne pas sentir l'horrible fardeau du Temps qui brise vos épaules et vous penche vers la terre, il faut vous enivrer sans trêve. \n",
      "\n",
      "(je|on|a) (espérer|désirer|décider) être (aussi|très|quelquefois|plutôt|néanmoins|complètement|bientôt|comment) (fougueux|insociable) . (seul|vingt-quatre|impossible) est là : c' est l' unique (histoire|phraser|article|science|oeuvrer|providence) . (chez) (peut-être|n|plutôt|davantage|certainement|comment) (jamais|nullement|plaire|plutôt|peut-être) (rendre|sembler|exprimer) l' (antithèse|inspiration|intimit) (idiome|tyrannie|fiction|déguisement|timidit) du (jour|partir|semaine|minuter|dimanche|mois|moment) (elles) (rouler|retomber|siffler|croiser) vos épaules (mai) vous penche (vers) la (intervalle|banc|muraille|remonter|ténèbres|fenêtre) , (je|on|a) (espérer|désirer|décider) vous (préalablement|panser|effaroucher) sans trêve .\n"
     ]
    }
   ],
   "source": [
    "print assertion, '\\n'\n",
    "print response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On espère être complètement fougueux. L’impossible est là : c’est l’unique œuvre. Pour davantage (peut-être) exprimer l’inspiration tyrannique du moment qui roule vos épaules et vous penche vers le banc, on espère vous effaroucher sans trêve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](Trump_tsne_plot.svg \"Word Vector Model for Trump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\">\n",
       "<p lang=\"en\" dir=\"ltr\">There are few issues more important to the security of\n",
       "the US than the potential spread of nuclear weapons or the potential for even\n",
       "more destructive war in the Middle East. Today’s decision to put the JCPOA at\n",
       "risk is a serious mistake. My full statement:\n",
       "<a href=\"https://t.co/4oTdXESbxe\">https://t.co/4oTdXESbxe</a></p>&mdash;\n",
       "Barack Obama (@BarackObama)\n",
       "<a href=\"https://twitter.com/BarackObama/status/993938824752451586?ref_src=twsrc%5Etfw\">May 8, 2018</a>\n",
       "</blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\">\n",
    "<p lang=\"en\" dir=\"ltr\">There are few issues more important to the security of\n",
    "the US than the potential spread of nuclear weapons or the potential for even\n",
    "more destructive war in the Middle East. Today’s decision to put the JCPOA at\n",
    "risk is a serious mistake. My full statement:\n",
    "<a href=\"https://t.co/4oTdXESbxe\">https://t.co/4oTdXESbxe</a></p>&mdash;\n",
    "Barack Obama (@BarackObama)\n",
    "<a href=\"https://twitter.com/BarackObama/status/993938824752451586?ref_src=twsrc%5Etfw\">May 8, 2018</a>\n",
    "</blockquote> <script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "discourse = 'Trump'\n",
    "# There are four options for vector spaces of words, which represent\n",
    "# different discourses, or the ways in which language is used: Trump,\n",
    "# Balzac, Sand, Flaubert.\n",
    "# See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "assertion = u\"There are few issues more important to the security \" + \\\n",
    "            u\"of the US than the potential spread of nuclear \" + \\\n",
    "            u\"weapons or the potential for even more destructive \" + \\\n",
    "            u\"war in the Middle East. Today’s decision to put the \" + \\\n",
    "            u\"JCPOA at risk is a serious mistake.\"\n",
    "# This assertion, a tweet by Barack Obama on 8 May 2018, will be altered by word\n",
    "# substitutions based on the analogy below.\n",
    "\n",
    "positive = u'strong'\n",
    "negative = u'weak'\n",
    "# These two words establish the analogy for finding similar words in\n",
    "# the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(params[discourse][0])\n",
    "pickleFile = open(params[discourse][1], 'rb')\n",
    "posd = pickle.load(pickleFile)\n",
    "\n",
    "nlp = spacy.load(params[discourse][2])\n",
    "parsed = nlp(assertion)\n",
    "words = [(w.text.lower(), w.tag_, w.lemma_.lower()) for w in parsed]\n",
    "# Build a list of 3-tuples for each word in the asserted text:\n",
    "# (the word in the asserted text, its POS, its lemma)\n",
    "\n",
    "new_words = []\n",
    "\n",
    "for word in words:\n",
    "    try:\n",
    "        hits = []\n",
    "        # a list of vector space words to be built that will be similar to a word\n",
    "        # in the asserted text.\n",
    "        \n",
    "        psw = word[1].split('__')[0]\n",
    "        # The POS tag for a word in the asserted text.\n",
    "        \n",
    "        #print word[0], word[1], word[2] # for debugging\n",
    "        \n",
    "        for item in model.wv.most_similar(positive=[positive.lower(), word[2]],\n",
    "                                          negative=[negative.lower()],\n",
    "                                          topn=number_of_options):\n",
    "        # Take each word in the asserted text and look for similar words\n",
    "        # in the vector space based on the analogy.\n",
    "        \n",
    "            #print '\\t', item # for debugging\n",
    "            \n",
    "            if posd[item[0]]:\n",
    "            # does the vector-space word have a POS tag?\n",
    "            \n",
    "                psd = next(iter(posd[item[0]])).split('__')[0]\n",
    "                \n",
    "                #print '\\t\\t', psd # for debugging\n",
    "                \n",
    "                if (psw not in params[discourse][3]) and (psw == psd):\n",
    "                # We exclude certain POS words (like determiners and punctuation: see above)\n",
    "                # to maintain readability in the invented text.\n",
    "                # We also select words from the vector space that are the same POS\n",
    "                # as the original word in the asserted text.\n",
    "                \n",
    "                    hits.append(item[0])\n",
    "                    \n",
    "        if len(hits) > 0:\n",
    "        # Did we find at least one vector space word with the same POS?\n",
    "        # If so, display them in parentheses in the invented text.\n",
    "        \n",
    "            replacement = '(' + '|'.join(hits) + ')'\n",
    "            new_words.append(replacement)\n",
    "            \n",
    "        else:\n",
    "        # If we found nothing that matches, use the original word.\n",
    "        \n",
    "            new_words.append(word[0])\n",
    "    except:\n",
    "    # If something weird happens, just use the original word.\n",
    "    \n",
    "        new_words.append(word[0])\n",
    "        \n",
    "        #print 'EXCEPTION', word[0] # for debugging\n",
    "\n",
    "response = ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are few issues more important to the security of the US than the potential spread of nuclear weapons or the potential for even more destructive war in the Middle East. Today’s decision to put the JCPOA at risk is a serious mistake. \n",
      "\n",
      "there (tell) (low) issues more (beautiful|low|happy) to the security of the (gop|maga|state) than the (low) spread of (low) (congratulation) or the potential for (then) more (exceptional) war in the (w|gop) (sunday|hotel|university) . (tomorrow|poll) ’s (gift) to put the jcpoa at (chairman|class|food) is a (important|low) (job|friend|hope) .\n"
     ]
    }
   ],
   "source": [
    "print assertion, '\\n'\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'move', 0.9992275238037109), (u'important', 0.9991986155509949), (u'tax', 0.9991898536682129), (u'yet', 0.9991799592971802), (u'pay', 0.9991798400878906), (u'bill', 0.9991753101348877), (u'us', 0.9991708993911743), (u'low', 0.9991667866706848), (u'other', 0.9991663694381714), (u'justice', 0.9991630911827087), (u'cut', 0.9991627335548401), (u'release', 0.999162495136261), (u'put', 0.9991592168807983), (u'china', 0.9991582632064819), (u'major', 0.9991567730903625)]\n"
     ]
    }
   ],
   "source": [
    "print model.wv.most_similar(positive=[positive, u'serious'],\n",
    "                            negative=[negative], topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'now', 0.9994233250617981), (u'to', 0.9994038939476013), (u'fight', 0.999396800994873), (u'proud', 0.9993846416473389), (u'job', 0.9993821978569031), (u'start', 0.9993764758110046), (u'tough', 0.9993470907211304), (u'will', 0.9993371963500977), (u'deal', 0.9993306994438171), (u'a', 0.9993232488632202), (u'once', 0.9993203282356262), (u'friend', 0.9993187785148621), (u'man', 0.999317467212677), (u'hope', 0.9993098974227905), (u'order', 0.99930739402771)]\n"
     ]
    }
   ],
   "source": [
    "print model.wv.most_similar(positive=[positive, u'mistake'],\n",
    "                            negative=[negative], topn=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"2100\"\n",
       "            height=\"800\"\n",
       "            src=\"http://www.alamo.free.fr/pmwiki.php?n=Logiciels.Programmes\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a22013c10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('http://www.alamo.free.fr/pmwiki.php?n=Logiciels.Programmes', 2100, 800)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "livereveal": {
   "scroll": true,
   "theme": "simple",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
