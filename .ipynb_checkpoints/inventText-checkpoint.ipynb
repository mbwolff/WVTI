{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Algorithmic Invention\n",
    "### Mark Wolff<br>Hartwick College\n",
    "#### ELO 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Canons of Rhetoric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Invention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Disposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Elocution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Delivery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "```\n",
    ">>> model.wv.most_similar(positive=['femme', 'roi'],\n",
    "        negative=['homme'], topn=1)\n",
    "[(u'reine', 0.8085041046142578)]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"2500\"\n",
       "            height=\"800\"\n",
       "            src=\"http://www.ghostweather.com/files/word2vecpride/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1076e0a90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame('http://www.ghostweather.com/files/word2vecpride/', 2500, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](NCF_Flaubert_tsne_plot.png \"t-SNE of Word Vector Model for Flaubert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import gensim\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "discourse = 'Flaubert'\n",
    "# There are two options for vector spaces of words, which represent\n",
    "# different discourses, or the ways in which language is used:\n",
    "# Flaubert and Russian Trolls.\n",
    "# See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "assertion = u\"Il faut être toujours ivre. Tout est là : \" + \\\n",
    "    u\"c'est l'unique question. Pour ne pas sentir l'horrible \" + \\\n",
    "    u\"fardeau du Temps qui brise vos épaules et vous penche \" + \\\n",
    "    u\"vers la terre, il faut vous enivrer sans trêve.\"\n",
    "# The assertion, from Baudelaire's poem Enivrez-vous!, will be altered\n",
    "# by word substitutions based on the analogy below.\n",
    "\n",
    "positive = [u'bien']\n",
    "negative = [u'mal']\n",
    "# These two words establish the analogy for finding similar words in\n",
    "# the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Flaubert':\n",
    "        ['NCF_Flaubert_model',\n",
    "         # vector space of words from 30 volumes by Flaubert\n",
    "         \n",
    "         'NCF_pos_dict.pkl',\n",
    "        # a dictionary of all words in the vector space with\n",
    "         # part-of-speech (POS) tags\n",
    "\n",
    "         'fr',\n",
    "         # the language of the vector space\n",
    "         \n",
    "         ('DET', 'PUNCT')\n",
    "         # POS tags for words that will not be replaced in asserted\n",
    "         # text\n",
    "        ],\n",
    "    'RussianTrolls':\n",
    "        ['RussianTrolls_model',\n",
    "         # a vector space of words from the Russian Troll tweets\n",
    "         # shared by fivethirtyeight\n",
    "         \n",
    "         'RussianTrolls_pos_dict.pkl',\n",
    "         \n",
    "         'en',\n",
    "         \n",
    "         ('DT', 'PUNCT', 'IN')\n",
    "        ]\n",
    "}\n",
    "\n",
    "number_of_options = 15\n",
    "# the max number of similar words proposed from the vector space\n",
    "# for each word in the asserted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(params[discourse][0])\n",
    "pickleFile = open(params[discourse][1], 'rb')\n",
    "posd = pickle.load(pickleFile)\n",
    "\n",
    "nlp = spacy.load(params[discourse][2])\n",
    "parsed = nlp(assertion)\n",
    "words = [(w.text.lower(), w.tag_, w.lemma_.lower()) for w in parsed]\n",
    "# Build a list of 3-tuples for each word in the asserted text:\n",
    "# (the word in the asserted text, its POS, its lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "new_words = []\n",
    "for word in words:\n",
    "    try:\n",
    "        hits = []\n",
    "        # a list of vector space words to be built that will be similar\n",
    "        # to a word in the asserted text.\n",
    "        psw = word[1].split('__')[0]\n",
    "        # The POS tag for a word in the asserted text.\n",
    "        for item in model.wv.most_similar(positive=positive + [word[2]],\n",
    "                                          negative=negative,\n",
    "                                          topn=number_of_options):\n",
    "        # Take each word in the asserted text and look for similar words\n",
    "        # in the vector space based on the analogy.\n",
    "            if posd[item[0]]:\n",
    "            # does the vector-space word have a POS tag?\n",
    "                psd = next(iter(posd[item[0]])).split('__')[0]\n",
    "                if (psw not in params[discourse][3]) and (psw == psd):\n",
    "                # We exclude certain POS words (like determiners and\n",
    "                # punctuation: see above) to maintain readability in\n",
    "                # the invented text. We also select words from the\n",
    "                # vector space that are the same POS as the original\n",
    "                # word in the asserted text.\n",
    "                    hits.append(item[0])\n",
    "        if len(hits) > 0:\n",
    "        # Did we find at least one vector space word with the same POS?\n",
    "        # If so, display them in parentheses in the invented text.\n",
    "            replacement = '(' + '|'.join(hits) + ')'\n",
    "            new_words.append(replacement)\n",
    "        else:\n",
    "        # If we found nothing that matches, use the original word.\n",
    "            new_words.append(word[0])\n",
    "    except:\n",
    "    # If something weird happens, just use the original word.\n",
    "        new_words.append(word[0])\n",
    "response = ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il faut être toujours ivre. Tout est là : c'est l'unique question. Pour ne pas sentir l'horrible fardeau du Temps qui brise vos épaules et vous penche vers la terre, il faut vous enivrer sans trêve. \n",
      "\n",
      "(je|on|a) (espérer|désirer|décider) être (aussi|très|quelquefois|plutôt|néanmoins|complètement|bientôt|comment) (fougueux|insociable) . (seul|vingt-quatre|impossible) est là : c' est l' unique (histoire|phraser|article|science|oeuvrer|providence) . (chez) (peut-être|n|plutôt|davantage|certainement|comment) (jamais|nullement|plaire|plutôt|peut-être) (rendre|sembler|exprimer) l' (antithèse|inspiration|intimit) (idiome|tyrannie|fiction|déguisement|timidit) du (jour|partir|semaine|minuter|dimanche|mois|moment) (elles) (rouler|retomber|siffler|croiser) vos épaules (mai) vous penche (vers) la (intervalle|banc|muraille|remonter|ténèbres|fenêtre) , (je|on|a) (espérer|désirer|décider) vous (préalablement|panser|effaroucher) sans trêve .\n"
     ]
    }
   ],
   "source": [
    "print assertion, '\\n'\n",
    "print response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "On espère être complètement fougueux. L’impossible est là : c’est l’unique œuvre. Pour davantage (peut-être) exprimer l’inspiration tyrannique du moment qui roule vos épaules et vous penche vers le banc, on espère vous effaroucher sans trêve.\n",
    "\n",
    "– Flaubertelaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](RussianTrolls_tsne_plot.png \"t-SNE of Word Vector Model for Russian Trolls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-lang=\"en\">\n",
       "<p lang=\"en\" dir=\"ltr\">&quot;No one is born hating another person because of the\n",
       "color of his skin or his background or his religion...&quot;\n",
       "<a href=\"https://t.co/InZ58zkoAm\">pic.twitter.com/InZ58zkoAm</a>\n",
       "</p>&mdash; Barack Obama (@BarackObama)\n",
       "<a href=\"https://twitter.com/BarackObama/status/896523232098078720?ref_src=twsrc%5Etfw\">August 13, 2017</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\">\n",
    "<p lang=\"en\" dir=\"ltr\">&quot;No one is born hating another person because of the\n",
    "color of his skin or his background or his religion...&quot;\n",
    "<a href=\"https://t.co/InZ58zkoAm\">pic.twitter.com/InZ58zkoAm</a>\n",
    "</p>&mdash; Barack Obama (@BarackObama)\n",
    "<a href=\"https://twitter.com/BarackObama/status/896523232098078720?ref_src=twsrc%5Etfw\">August 13, 2017</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-lang=\"en\">\n",
       "<p lang=\"en\" dir=\"ltr\">&quot;People must learn to hate, and if they can learn to hate,\n",
       "they can be taught to love...&quot;</p>&mdash; Barack Obama (@BarackObama)\n",
       "<a href=\"https://twitter.com/BarackObama/status/896523304873238528?ref_src=twsrc%5Etfw\">August 13, 2017</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-lang=\"en\">\n",
    "<p lang=\"en\" dir=\"ltr\">&quot;People must learn to hate, and if they can learn to hate,\n",
    "they can be taught to love...&quot;</p>&mdash; Barack Obama (@BarackObama)\n",
    "<a href=\"https://twitter.com/BarackObama/status/896523304873238528?ref_src=twsrc%5Etfw\">August 13, 2017</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-lang=\"en\">\n",
       "<p lang=\"en\" dir=\"ltr\">&quot;...For love comes more naturally to the human heart\n",
       "than its opposite.&quot; - Nelson Mandela</p>&mdash; Barack Obama (@BarackObama)\n",
       "<a href=\"https://twitter.com/BarackObama/status/896523357272911872?ref_src=twsrc%5Etfw\">August 13, 2017</a></blockquote>\n",
       "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<blockquote class=\"twitter-tweet\" data-conversation=\"none\" data-lang=\"en\">\n",
    "<p lang=\"en\" dir=\"ltr\">&quot;...For love comes more naturally to the human heart\n",
    "than its opposite.&quot; - Nelson Mandela</p>&mdash; Barack Obama (@BarackObama)\n",
    "<a href=\"https://twitter.com/BarackObama/status/896523357272911872?ref_src=twsrc%5Etfw\">August 13, 2017</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "discourse = 'RussianTrolls'\n",
    "# There are two options for vector spaces of words, which represent\n",
    "# different discourses, or the ways in which language is used:\n",
    "# Flaubert and Russian Trolls.\n",
    "# See below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "assertion = u\"No one is born hating another person because of the \" + \\\n",
    "    u\"color of his skin or his background or his religion. People \" + \\\n",
    "    u\"must learn to hate, and if they can learn to hate, they can \" + \\\n",
    "    u\"be taught to love. For love comes more naturally to the \" + \\\n",
    "    u\"human heart than its opposite.\"\n",
    "# The assertion, a tweet by Barack Obama posted August 12, 2017\n",
    "# quoting Nelson Mandela, will be altered by word substitutions\n",
    "# based on the analogy below.\n",
    "\n",
    "positive = [u'white', u'charlottesville']\n",
    "negative = [u'minority']\n",
    "# These words establish the analogy for finding similar words in\n",
    "# the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(params[discourse][0])\n",
    "pickleFile = open(params[discourse][1], 'rb')\n",
    "posd = pickle.load(pickleFile)\n",
    "\n",
    "nlp = spacy.load(params[discourse][2])\n",
    "parsed = nlp(assertion)\n",
    "words = [(w.text.lower(), w.tag_, w.lemma_.lower()) for w in parsed]\n",
    "# Build a list of 3-tuples for each word in the asserted text:\n",
    "# (the word in the asserted text, its POS, its lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "new_words = []\n",
    "for word in words:\n",
    "    try:\n",
    "        hits = []\n",
    "        # a list of vector space words to be built that will be similar\n",
    "        # to a word in the asserted text.\n",
    "        psw = word[1].split('__')[0]\n",
    "        # The POS tag for a word in the asserted text.\n",
    "        for item in model.wv.most_similar(positive=positive + [word[2]],\n",
    "                                          negative=negative,\n",
    "                                          topn=number_of_options):\n",
    "        # Take each word in the asserted text and look for similar words\n",
    "        # in the vector space based on the analogy.\n",
    "            if posd[item[0]]:\n",
    "            # does the vector-space word have a POS tag?\n",
    "                psd = next(iter(posd[item[0]])).split('__')[0]\n",
    "                if (psw not in params[discourse][3]) and (psw == psd):\n",
    "                # We exclude certain POS words (like determiners and\n",
    "                # punctuation: see above) to maintain readability in\n",
    "                # the invented text. We also select words from the\n",
    "                # vector space that are the same POS as the original\n",
    "                # word in the asserted text.\n",
    "                    hits.append(item[0])\n",
    "        if len(hits) > 0:\n",
    "        # Did we find at least one vector space word with the same POS?\n",
    "        # If so, display them in parentheses in the invented text.\n",
    "            replacement = '(' + '|'.join(hits) + ')'\n",
    "            new_words.append(replacement)\n",
    "        else:\n",
    "        # If we found nothing that matches, use the original word.\n",
    "            new_words.append(word[0])\n",
    "    except:\n",
    "    # If something weird happens, just use the original word.\n",
    "        new_words.append(word[0])\n",
    "response = ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No one is born hating another person because of the color of his skin or his background or his religion. People must learn to hate, and if they can learn to hate, they can be taught to love. For love comes more naturally to the human heart than its opposite. \n",
      "\n",
      "no (racism) is born hating another (shooter|racism) because of the (racism|hate|firsttimeisawme) of his (racism|hate) or his (judiciary|effigy) or his (racism) . people must (complain|write) to hate , and if they (should) (complain|write) to hate , they (should) be (embolden) to love . for (hate|racism) (hang) more naturally to the (violent|gay|leftist) (racism|hate) than its (irony|epitome|racism|symbol) .\n"
     ]
    }
   ],
   "source": [
    "print assertion, '\\n'\n",
    "print response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![alt text](FirstTimeISawMe.png \"\\#FirstTimeISawMe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"2500\"\n",
       "            height=\"800\"\n",
       "            src=\"http://www.alamo.free.fr/pmwiki.php?n=Logiciels.Programmes\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1a2cda9d50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame('http://www.alamo.free.fr/pmwiki.php?n=Logiciels.Programmes', 2500, 800)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "livereveal": {
   "scroll": true,
   "theme": "simple",
   "transition": "slide"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
